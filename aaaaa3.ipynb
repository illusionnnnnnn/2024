{"cells":[{"cell_type":"markdown","metadata":{},"source":["# ğŸ‘¾Qwen2å¤§æ¨¡å‹å¾®è°ƒå…¥é—¨\n","\n","ä½œè€…ï¼šæ—æ³½æ¯…\n","\n","æ•™ç¨‹æ–‡ç« ï¼šhttps://zhuanlan.zhihu.com/p/702491999  \n","\n","æ˜¾å­˜è¦æ±‚ï¼š10GBå·¦å³  \n","\n","å®éªŒè¿‡ç¨‹çœ‹ï¼šhttps://swanlab.cn/@ZeyiLin/Qwen2-fintune/runs/cfg5f8dzkp6vouxzaxlx6/chart"]},{"cell_type":"markdown","metadata":{},"source":["## 1.å®‰è£…ç¯å¢ƒ1\n","\n","æœ¬æ¡ˆä¾‹æµ‹è¯•äºmodelscope==1.14.0ã€transformers==4.41.2ã€datasets==2.18.0ã€peft==0.11.1ã€accelerate==0.30.1ã€swanlab==0.3.9"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%pip install torch swanlab modelscope transformers datasets peft pandas accelerate"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":["å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡ä½¿ç”¨SwanLabï¼Œåˆ™å‰å¾€[SwanLab](https://swanlab.cn)æ³¨å†Œè´¦å·åï¼Œåœ¨[ç”¨æˆ·è®¾ç½®](https://swanlab.cn/settings/overview)å¤åˆ¶API Keyï¼Œå¦‚æœæ‰§è¡Œä¸‹é¢çš„ä»£ç ï¼š"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## 2. æ•°æ®é›†åŠ è½½\n","\n","1. åœ¨[zh_cls_fudan-news - modelscope](https://modelscope.cn/datasets/huangjintao/zh_cls_fudan-news/files)ä¸‹è½½train.jsonlå’Œtest.jsonlåˆ°åŒçº§ç›®å½•ä¸‹ã€‚\n","\n","<img src=\"../assets/dataset.png\" width=600>"]},{"cell_type":"markdown","metadata":{},"source":["2. å°†train.jsonlå’Œtest.jsonlè¿›è¡Œå¤„ç†ï¼Œè½¬æ¢æˆnew_train.jsonlå’Œnew_test.jsonl"]},{"cell_type":"code","execution_count":5,"metadata":{"trusted":true},"outputs":[],"source":["import pandas as pd\n","import json\n","import os\n","\n","def dataset_tsv_to_jsonl(origin_path, new_path):\n","    \"\"\"\n","    å°† TSV æ•°æ®é›†è½¬æ¢ä¸º JSONL æ ¼å¼\n","    \"\"\"\n","    df = pd.read_csv(origin_path, sep='\\t')\n","\n","    # å®šä¹‰è¦ä¿å­˜çš„æ¶ˆæ¯ç»“æ„\n","    messages = []\n","\n","    for index, row in df.iterrows():\n","        message = {\n","            \"instruction\": \"æ ¹æ®ä»¥ä¸‹è¯„è®ºå†…å®¹ï¼Œé¢„æµ‹è¯„è®ºè€…çš„ä¸ªæ€§ç‰¹è´¨ã€‚\",\n","            \"input\": row['comment'],\n","            \"output\": {\n","                \"personality_conscientiousness\": row['personality_conscientiousness'],\n","                \"personality_openess\": row['personality_openess'],\n","                \"personality_extraversion\": row['personality_extraversion'],\n","                \"personality_agreeableness\": row['personality_agreeableness'],\n","                \"personality_stability\": row['personality_stability']\n","            }\n","        }\n","        messages.append(message)\n","\n","    # ä¿å­˜é‡æ„åçš„ JSONL æ–‡ä»¶\n","    with open(new_path, \"w\", encoding=\"utf-8\") as file:\n","        for message in messages:\n","            file.write(json.dumps(message, ensure_ascii=False) + \"\\n\")\n","\n","# è®¾ç½®åŸå§‹ TSV æ–‡ä»¶å’Œç›®æ ‡ JSONL æ–‡ä»¶çš„è·¯å¾„\n","train_tsv_path = \"/home/wangyanan/transformer-code1/transformers-code/13-qwen2.5-7b/dataset/train.tsv\"  # å‡è®¾ TSV æ–‡ä»¶ä½äºåŒä¸€ç›®å½•ä¸‹\n","new_train_path = \"/home/wangyanan/transformer-code1/transformers-code/13-qwen2.5-7b/dataset/new_personality_train.jsonl\"\n","\n","\n","# test_tsv_path = \"/kaggle/input/qwen25/test.tsv\"  # å‡è®¾ TSV æ–‡ä»¶ä½äºåŒä¸€ç›®å½•ä¸‹\n","# new_test_path = \"/kaggle/input/qwen25/new_personality_test.jsonl\"\n","# æ£€æŸ¥ç›®æ ‡æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨ï¼Œåˆ™æ‰§è¡Œè½¬æ¢\n","if not os.path.exists(new_train_path):\n","    dataset_tsv_to_jsonl(train_tsv_path, new_train_path)\n","\n","# if not os.path.exists(new_test_path):\n","#     dataset_tsv_to_jsonl(test_tsv_path, new_test_path)\n","\n","train_df = pd.read_json(new_train_path, lines=True)[:792]  # å–å‰1000æ¡åšè®­ç»ƒï¼ˆå¯é€‰ï¼‰\n","# test_df = pd.read_json(new_test_path, lines=True)[:10]  # å–å‰10æ¡åšä¸»è§‚è¯„æµ‹\n"]},{"cell_type":"markdown","metadata":{},"source":["## 3. ä¸‹è½½/åŠ è½½æ¨¡å‹å’Œtokenizer"]},{"cell_type":"code","execution_count":3,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-10-14 11:29:00,775 - modelscope - WARNING - Using branch: master as version is unstable, use with caution\n","Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.40s/it]\n"]}],"source":["from modelscope import snapshot_download, AutoTokenizer\n","from transformers import AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForSeq2Seq\n","import torch\n","\n","# åœ¨modelscopeä¸Šä¸‹è½½Qwenæ¨¡å‹åˆ°æœ¬åœ°ç›®å½•ä¸‹\n","model_dir = snapshot_download(\"Qwen/Qwen2.5-7B\", cache_dir=\"./\", revision=\"master\")\n","\n","# TransformersåŠ è½½æ¨¡å‹æƒé‡\n","tokenizer = AutoTokenizer.from_pretrained(\"./Qwen/Qwen2___5-7B/\", use_fast=False, trust_remote_code=True)\n","model = AutoModelForCausalLM.from_pretrained(\"./Qwen/Qwen2___5-7B/\", device_map=\"auto\", torch_dtype=torch.bfloat16)\n","model.enable_input_require_grads()  # å¼€å¯æ¢¯åº¦æ£€æŸ¥ç‚¹æ—¶ï¼Œè¦æ‰§è¡Œè¯¥æ–¹æ³•"]},{"cell_type":"markdown","metadata":{},"source":["## 4. é¢„å¤„ç†è®­ç»ƒæ•°æ®"]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'process_func' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[1;32m      3\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m Dataset\u001b[38;5;241m.\u001b[39mfrom_pandas(train_df)\n\u001b[0;32m----> 4\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m train_ds\u001b[38;5;241m.\u001b[39mmap(\u001b[43mprocess_func\u001b[49m, remove_columns\u001b[38;5;241m=\u001b[39mtrain_ds\u001b[38;5;241m.\u001b[39mcolumn_names)\n","\u001b[0;31mNameError\u001b[0m: name 'process_func' is not defined"]}],"source":["from datasets import Dataset\n","\n","train_ds = Dataset.from_pandas(train_df)\n","train_dataset = train_ds.map(process_func, remove_columns=train_ds.column_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torch\n","from transformers import AutoTokenizer\n","\n","# # åˆå§‹åŒ–tokenizerï¼Œè¿™é‡Œéœ€è¦æ‚¨æ ¹æ®å®é™…æƒ…å†µæ›¿æ¢ä¸ºæ‚¨çš„æ¨¡å‹å¯¹åº”çš„tokenizer\n","# tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n","\n","def process_func(example):\n","    \"\"\"\n","    å°†æ•°æ®é›†è¿›è¡Œé¢„å¤„ç†\n","    \"\"\"\n","    MAX_LENGTH = 384\n","    input_ids, attention_mask = [], []\n","    \n","    # æ„å»ºæŒ‡ä»¤éƒ¨åˆ†\n","    instruction = tokenizer(\n","        f\"<|im_start|>system\\n{example['instruction']}<|im_end|>\\n<|im_start|>user\\n{example['input']}<|im_end|>\\n<|im_start|>assistant\\n\",\n","        add_special_tokens=False,\n","    )\n","    \n","    # æ„å»ºå“åº”éƒ¨åˆ†ï¼Œå³è¾“å‡ºéƒ¨åˆ†\n","    response = tokenizer(\"\", add_special_tokens=False)  # è¿™é‡Œä¸éœ€è¦å†æ¬¡è¿›è¡Œtokenizerå¤„ç†\n","    \n","    # åˆå¹¶æŒ‡ä»¤å’Œå“åº”çš„input_idså’Œattention_mask\n","    input_ids = instruction[\"input_ids\"] + response[\"input_ids\"]\n","    attention_mask = instruction[\"attention_mask\"] + response[\"attention_mask\"]\n","    \n","    # å¦‚æœé•¿åº¦è¶…è¿‡MAX_LENGTHï¼Œè¿›è¡Œæˆªæ–­\n","    if len(input_ids) > MAX_LENGTH:\n","        input_ids = input_ids[:MAX_LENGTH]\n","        attention_mask = attention_mask[:MAX_LENGTH]\n","    \n","    # å°†labelsè½¬æ¢ä¸ºæµ®ç‚¹æ•°ç±»å‹çš„å¼ é‡\n","    labels = []\n","    for key in ['personality_conscientiousness', 'personality_openess', 'personality_extraversion', 'personality_agreeableness', 'personality_stability']:\n","        try:\n","            labels.append(float(example['output'][key]))\n","        except (ValueError, KeyError):\n","            # å¦‚æœè½¬æ¢å¤±è´¥æˆ–é”®ä¸å­˜åœ¨ï¼Œå¯ä»¥ç”¨0æˆ–å¹³å‡å€¼å¡«å……ï¼Œæˆ–è€…é€‰æ‹©è·³è¿‡è¿™ä¸ªæ ·æœ¬\n","            labels.append(0)  # æˆ–è€…é€‰æ‹©å…¶ä»–åˆé€‚çš„é»˜è®¤å€¼\n","    \n","    labels = torch.tensor(labels, dtype=torch.float)\n","    \n","    return {\n","        \"input_ids\": input_ids + [tokenizer.pad_token_id],  # æ·»åŠ padding\n","        \"attention_mask\": attention_mask + [1],  # æ·»åŠ padding\n","        \"labels\": labels\n","    }\n","\n","# ç¤ºä¾‹æ•°æ®\n","example = {\n","    \"instruction\": \"æ ¹æ®ä»¥ä¸‹è¯„è®ºå†…å®¹ï¼Œé¢„æµ‹è¯„è®ºè€…çš„ä¸ªæ€§ç‰¹è´¨ã€‚\",\n","    \"input\": \"It breaks my heart to see people living in those conditions...\",\n","    \"output\": {\n","        \"personality_conscientiousness\": \"7\",\n","        \"personality_openess\": \"5.5\",\n","        \"personality_extraversion\": \"1\",\n","        \"personality_agreeableness\": \"6.5\",\n","        \"personality_stability\": \"6\"\n","    }\n","}\n","\n","# æµ‹è¯•process_funcå‡½æ•°\n","processed_example = process_func(example)\n","print(processed_example)"]},{"cell_type":"markdown","metadata":{},"source":["## 5. è®¾ç½®LORA"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from peft import LoraConfig, TaskType, get_peft_model\n","\n","config = LoraConfig(\n","    task_type=TaskType.CAUSAL_LM,\n","    target_modules=[\n","        \"q_proj\",\n","        \"k_proj\",\n","        \"v_proj\",\n","        \"o_proj\",\n","        \"gate_proj\",\n","        \"up_proj\",\n","        \"down_proj\",\n","    ],\n","    inference_mode=False,  # è®­ç»ƒæ¨¡å¼\n","    r=8,  # Lora ç§©\n","    lora_alpha=32,  # Lora alaphï¼Œå…·ä½“ä½œç”¨å‚è§ Lora åŸç†\n","    lora_dropout=0.1,  # Dropout æ¯”ä¾‹\n",")\n","\n","model = get_peft_model(model, config)"]},{"cell_type":"markdown","metadata":{},"source":["## 6. è®­ç»ƒ"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["args = TrainingArguments(\n","    output_dir=\"./output/Qwen2-personality\",\n","    per_device_train_batch_size=2,\n","    gradient_accumulation_steps=111,\n","    logging_steps=10,\n","    num_train_epochs=4,\n","    save_steps=100,\n","    learning_rate=1e-4,\n","    save_on_each_node=True,\n","    gradient_checkpointing=True,\n","    report_to=\"none\",\n","   \n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from swanlab.integration.huggingface import SwanLabCallback\n","import swanlab\n","\n","swanlab_callback = SwanLabCallback(\n","    project=\"Qwen2-fintune\",\n","    experiment_name=\"Qwen2-1.5B-Instruct\",\n","    description=\"ä½¿ç”¨é€šä¹‰åƒé—®Qwen2-1.5B-Instructæ¨¡å‹åœ¨personalityæ•°æ®é›†ä¸Šå¾®è°ƒã€‚\",\n","    config={\n","        \"model\": \"qwen/Qwen2-1.5B-Instruct\",\n","        \"dataset\": \"illusion/personality\",\n","    },\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["trainer = Trainer(\n","    model=model,\n","    args=args,\n","    train_dataset=train_dataset,\n","    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True),\n","    callbacks=[swanlab_callback],\n",")\n","\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# ====== è®­ç»ƒç»“æŸåçš„é¢„æµ‹ ===== #\n","\n","def predict(messages, model, tokenizer):\n","    device = \"cuda\"\n","    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n","    model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n","    generated_ids = model.generate(model_inputs.input_ids, max_new_tokens=512)\n","    generated_ids = [\n","        output_ids[len(input_ids) :]\n","        for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n","    ]\n","\n","    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n","    print(response)\n","\n","    return response\n","    \n","\n","test_text_list = []\n","for index, row in test_df.iterrows():\n","    instruction = row[\"instruction\"]\n","    input_value = row[\"input\"]\n","\n","    messages = [\n","        {\"role\": \"system\", \"content\": f\"{instruction}\"},\n","        {\"role\": \"user\", \"content\": f\"{input_value}\"},\n","    ]\n","\n","    response = predict(messages, model, tokenizer)\n","    messages.append({\"role\": \"assistant\", \"content\": f\"{response}\"})\n","    result_text = f\"{messages[0]}\\n\\n{messages[1]}\\n\\n{messages[2]}\"\n","    test_text_list.append(swanlab.Text(result_text, caption=response))\n","\n","swanlab.log({\"Prediction\": test_text_list})\n","swanlab.finish()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["=======\n","import pandas as pd\n","import torch\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer\n","\n","# å‡è®¾æ¨¡å‹å’Œåˆ†è¯å™¨å·²ç»è¢«æ­£ç¡®åˆå§‹åŒ–\n","# model = AutoModelForSequenceClassification.from_pretrained('model_name')\n","# tokenizer = AutoTokenizer.from_pretrained('model_name')\n","\n","def predict(input_text, model, tokenizer):\n","    \"\"\"\n","    ä½¿ç”¨æ¨¡å‹é¢„æµ‹æ€§æ ¼ç‰¹è´¨è¯„åˆ†\n","    \"\"\"\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    input_ids = tokenizer(input_text, return_tensors=\"pt\").to(device)\n","    with torch.no_grad():\n","        outputs = model(input_ids['input_ids'])\n","        logits = outputs.logits\n","        predictions = torch.softmax(logits, dim=-1)\n","    return predictions.cpu().numpy()[0]\n","\n","# æµ‹è¯•æ•°æ®\n","predictions_list = []\n","for index, row in test_df.iterrows():\n","    input_text = row['comment']\n","    predictions = predict(input_text, model, tokenizer)\n","    \n","    # å°†é¢„æµ‹ç»“æœæ·»åŠ åˆ°åˆ—è¡¨\n","    predictions_list.append({\n","        \"personality_conscientiousness\": predictions[0],\n","        \"personality_openess\": predictions[1],\n","        \"personality_extraversion\": predictions[2],\n","        \"personality_agreeableness\": predictions[3],\n","        \"personality_stability\": predictions[4]\n","    })\n","\n","# å°†é¢„æµ‹ç»“æœè½¬æ¢ä¸º DataFrame\n","predictions_df = pd.DataFrame(predictions_list)\n","\n","# ä¿å­˜ DataFrame ä¸º TSV æ–‡ä»¶\n","output_file_path = \"/home/wangyanan/transformer-code1/transformers-code/12-qwen2.5-7b/Qwen/LLM-Finetune/dataset/predictions.tsv\"\n","predictions_df.to_csv(output_file_path, sep='\\t', index=False)\n","\n","print(f\"é¢„æµ‹ç»“æœå·²ä¿å­˜è‡³ï¼š{output_file_path}\")"]},{"cell_type":"code","execution_count":128,"metadata":{"execution":{"iopub.execute_input":"2024-10-12T15:58:04.710864Z","iopub.status.busy":"2024-10-12T15:58:04.710454Z","iopub.status.idle":"2024-10-12T15:58:04.716538Z","shell.execute_reply":"2024-10-12T15:58:04.715509Z","shell.execute_reply.started":"2024-10-12T15:58:04.710828Z"},"trusted":true},"outputs":[],"source":["from swanlab.integration.huggingface import SwanLabCallback\n","import swanlab\n","\n","swanlab_callback = SwanLabCallback(\n","    project=\"Qwen2-fintune\",\n","    experiment_name=\"Qwen2-1.5B-Instruct\",\n","    description=\"ä½¿ç”¨é€šä¹‰åƒé—®Qwen2-1.5B-Instructæ¨¡å‹åœ¨personalityæ•°æ®é›†ä¸Šå¾®è°ƒã€‚\",\n","    config={\n","        \"model\": \"qwen/Qwen2-1.5B-Instruct\",\n","        \"dataset\": \"illusion/personality\",\n","    },\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-12T15:58:15.691845Z","iopub.status.busy":"2024-10-12T15:58:15.691137Z","iopub.status.idle":"2024-10-12T15:59:47.263664Z","shell.execute_reply":"2024-10-12T15:59:47.262664Z","shell.execute_reply.started":"2024-10-12T15:58:15.691804Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import json\n","import os\n","from modelscope import snapshot_download, AutoTokenizer\n","from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n","import torch\n","import torch.nn as nn\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","def dataset_tsv_to_jsonl(origin_path, new_path):\n","    df = pd.read_csv(origin_path, sep='\\t')\n","    messages = []\n","    for index, row in df.iterrows():\n","        message = {\n","            \"instruction\": \"æ ¹æ®ä»¥ä¸‹è¯„è®ºå†…å®¹ï¼Œé¢„æµ‹è¯„è®ºè€…çš„ä¸ªæ€§ç‰¹è´¨ã€‚\",\n","            \"input\": row['comment'],\n","            \"output\": {\n","                \"personality_conscientiousness\": row['personality_conscientiousness'],\n","                \"personality_openess\": row['personality_openess'],\n","                \"personality_extraversion\": row['personality_extraversion'],\n","                \"personality_agreeableness\": row['personality_agreeableness'],\n","                \"personality_stability\": row['personality_stability']\n","            }\n","        }\n","        messages.append(message)\n","    with open(new_path, \"w\", encoding=\"utf-8\") as file:\n","        for message in messages:\n","            file.write(json.dumps(message, ensure_ascii=False) + \"\\n\")\n","\n","train_tsv_path = \"/home/wangyanan/transformer-code1/transformers-code/13-qwen2.5-7b/dataset/train.tsv\"\n","new_train_path = \"/home/wangyanan/transformer-code1/transformers-code/13-qwen2.5-7b/dataset/new_personality_train.jsonl\"\n","if not os.path.exists(new_train_path):\n","    dataset_tsv_to_jsonl(train_tsv_path, new_train_path)\n","\n","train_df = pd.read_json(new_train_path, lines=True)\n","\n","class PersonalityDataset(Dataset):\n","    def __init__(self, dataframe, tokenizer, max_length):\n","        self.dataframe = dataframe\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.dataframe)\n","\n","    def __getitem__(self, idx):\n","        item = self.dataframe.iloc[idx]\n","        inputs = self.tokenizer(\n","            item['input'],\n","            max_length=self.max_length,\n","            padding='max_length',\n","            truncation=True,\n","            return_attention_mask=True,\n","            return_tensors='pt'\n","        )\n","        labels = []\n","        for key in ['personality_conscientiousness', 'personality_openess', 'personality_extraversion', 'personality_agreeableness', 'personality_stability']:\n","            try:\n","                labels.append(float(item['output'][key]))\n","            except (ValueError, KeyError):\n","                labels.append(0)\n","        labels = torch.tensor(labels, dtype=torch.float)\n","        return {\n","            \"input_ids\": inputs['input_ids'].flatten(),\n","            \"attention_mask\": inputs['attention_mask'].flatten(),\n","            \"labels\": labels\n","        }\n","\n","# åŠ è½½é¢„è®­ç»ƒæ¨¡å‹å’Œtokenizer\n","\n","\n","# åŠ è½½åˆ†è¯å™¨å’Œæ¨¡å‹\n","tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n","model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=5)\n","\n","# ç°åœ¨æ¨¡å‹å’Œåˆ†è¯å™¨å·²ç»å‡†å¤‡å¥½ï¼Œå¯ä»¥ç”¨äºè¿›ä¸€æ­¥çš„å¤„ç†æˆ–è®­ç»ƒã€‚\n","\n","# æ›¿æ¢æœ€åçš„è¾“å‡ºå±‚ä»¥é€‚åº”å›å½’ä»»åŠ¡\n","model.classifier = nn.Linear(model.classifier.in_features, 5)  # å‡è®¾æœ‰5ä¸ªä¸ªæ€§ç‰¹è´¨åˆ†æ•°\n","\n","max_length = 384\n","dataset = PersonalityDataset(train_df, tokenizer, max_length)\n","batch_size = 8\n","train_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","\n","args = TrainingArguments(\n","    output_dir=\"./output/Qwen2-personality\",\n","    per_device_train_batch_size=batch_size,\n","    gradient_accumulation_steps=4,\n","    logging_steps=10,\n","    num_train_epochs=2,\n","    save_steps=100,\n","    learning_rate=1e-4,\n","    save_on_each_node=True,\n","    gradient_checkpointing=True,\n","    report_to=\"none\",\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=args,\n","    train_dataset=dataset,\n","    data_collator=None,  # ä½¿ç”¨é»˜è®¤çš„æ•°æ®æ•´ç†å™¨\n",")\n","\n","trainer.train()\n","swanlab.log({\"Prediction\": test_text_list})\n","swanlab.finish()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import json\n","import os\n","\n","from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n","import torch\n","import torch.nn as nn\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n","model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=5)\n"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5861494,"sourceId":9606811,"sourceType":"datasetVersion"},{"isSourceIdPinned":true,"modelId":137712,"modelInstanceId":114446,"sourceId":135304,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3.9.20 64-bit ('qwen': conda)","metadata":{"interpreter":{"hash":"aed5936ed1f22c449b9ef9e957a14c9173742fb3b917be219d501cac6fbc754b"}},"name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.20"}},"nbformat":4,"nbformat_minor":4}
